<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog on Kernelize</title>
    <link>http://localhost:1313/blog/</link>
    <description>Recent content in Blog on Kernelize</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 17 Jun 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Why Open-source is the Bridge</title>
      <link>http://localhost:1313/blog/why-open-source-is-the-bridge/</link>
      <pubDate>Tue, 17 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/why-open-source-is-the-bridge/</guid>
      <description></description>
    </item>
    <item>
      <title>The NPU Software Gap (The Path to Efficient AI, Part 2)</title>
      <link>http://localhost:1313/blog/the-npu-software-gap/</link>
      <pubDate>Wed, 11 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/the-npu-software-gap/</guid>
      <description></description>
    </item>
    <item>
      <title>Beyond CPUs and GPUs: The Rise of Specialized AI Hardware</title>
      <link>http://localhost:1313/blog/beyond-cpus-and-gpus/</link>
      <pubDate>Wed, 04 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/beyond-cpus-and-gpus/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;main.png&#34; alt=&#34;CPU and GPU architectures&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;CPUs and GPUs have been at the center of the AI boom, and the capabilities of AI models have grown exponentially while running on these traditional processors. With all of the impressive LLMs and generative AI models available today, it is easy to forget we are still in the early days of AI. Future AI models will need significantly more processing power.&lt;/p&gt;&#xA;&lt;p&gt;We have the deepest respect for the engineers that have stretched CPU and GPU hardware and software to support AI workloads. But, CPU and GPU hardware architectures were not designed for AI and we are increasingly hitting limits in efficiency and power consumption. Inference costs are inflated by running on hardware that was architected for other applications. A new kind of hardware architecture is needed to efficiently run AI workloads.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
