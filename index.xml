<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kernelize</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on Kernelize</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 01 May 2025 09:00:00 -0700</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Products</title>
      <link>http://localhost:1313/products/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/products/</guid>
      <description>&lt;p&gt;Kernelize uses and actively supports the open-source Triton compiler and language. Triton is widely used to describe optimized GPU kernels and we leverage Triton to quickly target and optimize for new AI accelerator hardware.&lt;/p&gt;&#xA;&lt;p&gt;Triton already supports autotune to search for supported and optimal kernels, so the main features needed to target new hardware are a modular backend and discovery-based runtime. Most AI frameworks and ML graph compilers already target Triton by default.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Open Core Ventures announces Kernelize</title>
      <link>http://localhost:1313/posts/welcome/</link>
      <pubDate>Thu, 01 May 2025 09:00:00 -0700</pubDate>
      <guid>http://localhost:1313/posts/welcome/</guid>
      <description>&lt;p&gt;Open Core Ventures (OCV) has just unveiled &lt;strong&gt;Kernelize Inc.&lt;/strong&gt;, an innovative AI compiler platform designed to “bridge the CUDA moat” by auto-generating optimized backends for a wide variety of hardware targets. Built on the open-source Triton compiler, Kernelize lets developers write high-performance GPU kernels in Python once and deploy them across GPUs, NPUs, TPUs, and more—eliminating lock-in to any single vendor’s proprietary stack. Founded by industry veteran Simon Waters, whose résumé includes leading AMD’s Triton contributions and co-creating the Catapult C Synthesis tool, Kernelize aims to democratize AI performance and accelerate hardware-agnostic innovation.&lt;/p&gt;</description>
    </item>
    <item>
      <title>About</title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/about/</guid>
      <description>&lt;p&gt;Our team includes experts with extensive experience in Triton and building systems for AI inference.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Contact</title>
      <link>http://localhost:1313/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/contact/</guid>
      <description>&lt;h1 id=&#34;contact-us&#34;&gt;Contact us&lt;/h1&gt;&#xA;&lt;p&gt;Please &lt;a href=&#34;mailto:simon@kernelize.ai&#34;&gt;Email Simon&lt;/a&gt; if you have any questions about Kernelize&lt;/p&gt;</description>
    </item>
    <item>
      <title>Jobs</title>
      <link>http://localhost:1313/jobs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/jobs/</guid>
      <description>&lt;p&gt;Welcome to our Jobs page!&lt;/p&gt;</description>
    </item>
    <item>
      <title>Pricing</title>
      <link>http://localhost:1313/pricing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/pricing/</guid>
      <description>&lt;p&gt;Looking for access to better AI Accelerator Hardware?&lt;/p&gt;&#xA;&lt;p&gt;Kernelize’s products will be released as soon as supported AI accelerator hardware is released. We will update this page with more information after each hardware release.&lt;/p&gt;&#xA;&lt;h2 id=&#34;ai-inference-accelerator-hardware-providers&#34;&gt;AI Inference Accelerator Hardware Providers&lt;/h2&gt;&#xA;&lt;p&gt;Our goal at Kernelize is to seamlessly move GPU workloads to your AI Inference hardware. We provide access to an open-source compiler and consistent AI inference solutions for AI inference hardware. Please contact &lt;!-- raw HTML omitted --&gt;&lt;a href=&#34;mailto:sales@kernelize.com&#34;&gt;sales@kernelize.com&lt;/a&gt;&lt;!-- raw HTML omitted --&gt; if you would like to know more about Kernelize supporting your hardware.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
